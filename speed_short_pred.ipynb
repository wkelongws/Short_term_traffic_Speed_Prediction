{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "from pylab import *\n",
    "from matplotlib import gridspec\n",
    "cdict = {'red': ((0.0, 1.0, 1.0),\n",
    "                 (0.125, 1.0, 1.0),\n",
    "                 (0.25, 1.0, 1.0),\n",
    "                 (0.5625, 1.0, 1.0),\n",
    "                 (1.0, 0.0, 0.0)),\n",
    "         'green': ((0.0, 0.0, 0.0),\n",
    "                   (0.25, 0.0, 0.0),\n",
    "                   (0.5625, 1.0, 1.0),\n",
    "                   (1.0, 1.0, 1.0)),\n",
    "         'blue': ((0.0, 0.0, 0.0),\n",
    "                  (0.5, 0.0, 0.0),\n",
    "                  (1.0, 0.0, 0.0))}\n",
    "my_cmap = matplotlib.colors.LinearSegmentedColormap('my_colormap',cdict,256)\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "#datapath = '/home/microway/Shuo/CarND/CarND-BehaviorCloning-Project/data-given/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_data(data,datafolder='Data_2016_DES_I235E/'):\n",
    "#     X_train = np.zeros((len(data),15,288,10))\n",
    "#     y_train = np.zeros((len(data),15,1440,3))\n",
    "#     for i in range(len(data)):\n",
    "#         with open(datafolder+'CSVs/'+data['X'][i], 'r') as f:\n",
    "#             X = list(csv.reader(f, delimiter=\",\"))\n",
    "#             X = np.asarray(X)\n",
    "#             channels = np.unique(X[:,0])\n",
    "#             for channel in channels:\n",
    "#                 index=X[:,0] == channel\n",
    "#                 X_train[i,:,:,int(channel)] = X[index,1:]\n",
    "#         with open(datafolder+'Traffic_CSVs/'+data['y'][i], 'r') as f:\n",
    "#             y = list(csv.reader(f, delimiter=\",\"))\n",
    "#             y = np.asarray(y)\n",
    "#             channels = np.unique(y[:,0])\n",
    "#             for channel in channels:\n",
    "#                 index=y[:,0] == channel\n",
    "#                 y_train[i,:,:,int(channel)] = y[index,1:]\n",
    "# #             index=y[:,0] == '0'\n",
    "# #             y_train[i,:,:,0] = y[index,1:]\n",
    "#     return X_train,y_train\n",
    "\n",
    "# def convert_zero_2_mean(y_train):\n",
    "#     y_train[y_train==0] = np.nan\n",
    "#     avg = np.nanmean(y_train, axis=0)\n",
    "#     arrays = [avg for _ in range(y_train.shape[0])]\n",
    "#     AVG = np.stack(arrays, axis=0)\n",
    "#     index = np.isnan(y_train)\n",
    "#     y_train[index] = AVG[index]\n",
    "#     y_train[np.isnan(y_train)] = np.nanmean(y_train)\n",
    "#     return y_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/Users/Shuo/study/Project-predictive_study/data_2016_I235E.csv',delimiter=',')\n",
    "# _,Traffic = load_data(data)\n",
    "# Traffic = np.swapaxes(Traffic,1,2)\n",
    "# Raw_Speed = Traffic[:,:,:,0]\n",
    "# Speed = convert_zero_2_mean(Raw_Speed)\n",
    "# Speed = np.reshape(Speed, (Speed.shape[0],Speed.shape[1], Speed.shape[2]))\n",
    "\n",
    "# print(Traffic.shape)\n",
    "# print(Raw_Speed.shape)\n",
    "# print(Speed.shape)\n",
    "\n",
    "# # print(Speed[16,:5,:])\n",
    "# # plt.pcolor(Speed[16,:,:],cmap=my_cmap)\n",
    "# print(np.count_nonzero(Speed==0))\n",
    "# print(np.count_nonzero(np.isnan(Speed)))\n",
    "\n",
    "# data['y'][0][:4]\n",
    "# data['day'] = data['y'].map(lambda x: x[:8])\n",
    "# data['date'] = pd.to_datetime(data['day'],format='%Y%m%d')\n",
    "# data['dayofweek'] = data['date'].map(lambda x: x.dayofweek)\n",
    "# data['dayofyear'] = data['date'].map(lambda x: x.dayofyear)\n",
    "# del data['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump( (Traffic,Speed,data), open( \"speed_short_term.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "(Traffic,Speed,data) = pickle.load( open( \"speed_short_term.p\", \"rb\" ) )\n",
    "print(Traffic.shape)\n",
    "print(Speed.shape)\n",
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shapeback(Y):\n",
    "    YY = np.reshape(Y[len(Y)%288:,:],(len(Y)//288,288,Y.shape[1]))\n",
    "    return np.swapaxes(YY,1,2)\n",
    "\n",
    "def create_dataset(Speed, look_back=6, mode='uni'):\n",
    "    \n",
    "    dataX,dataY = [],[]\n",
    "    \n",
    "    if mode == 'uni':\n",
    "        \n",
    "        for j in range(len(Speed)):\n",
    "            dataX_,dataY_ = [],[]\n",
    "            dataset = Speed[j,:,0:1]\n",
    "\n",
    "            for i in range(len(dataset)-look_back-1):\n",
    "                a = dataset[i:(i+look_back), :]\n",
    "                dataX_.append(a)\n",
    "                dataY_.append(dataset[i + look_back, :])\n",
    "                \n",
    "            dataX.append(numpy.array(dataX_))\n",
    "            dataY.append(numpy.array(dataY_))\n",
    "            \n",
    "    if mode == 'multi':\n",
    "        \n",
    "        for j in range(len(Speed)):\n",
    "            dataX_,dataY_ = [],[]\n",
    "            dataset = Speed[j,:,:]\n",
    "\n",
    "            for i in range(len(dataset)-look_back-1):\n",
    "                a = dataset[i:(i+look_back), :]\n",
    "                dataX_.append(a)\n",
    "                dataY_.append(dataset[i + look_back, :])\n",
    "                \n",
    "            dataX.append(numpy.array(dataX_))\n",
    "            dataY.append(numpy.array(dataY_))    \n",
    "                \n",
    "                \n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment1: speed to speed univariate, same day of week, stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_speed = Speed[-1:,:,:]\n",
    "dayofweek = data['dayofweek'][len(data)-1]\n",
    "train_speed = Speed[data.index[data['dayofweek'] == dayofweek],:,:]\n",
    "print('train_speed.shape = ',train_speed.shape)\n",
    "print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "look_back = 15\n",
    "mode = 'uni'\n",
    "train_speed_x,train_speed_y = create_dataset(train_speed, look_back, mode)\n",
    "test_speed_x,test_speed_y = create_dataset(test_speed, look_back, mode)\n",
    "print('look_back = ',look_back)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.plot(test_speed_y[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "for e in range(epochs):\n",
    "    for i in range(len(train_speed_x)):#len(train_speed_x)\n",
    "        model.fit(train_speed_x[i,:,:,:], train_speed_y[i,:,:], nb_epoch=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trainScore = [];\n",
    "# for i in range(len(train_speed_x)):\n",
    "#     trainScore.append(model.evaluate(train_speed_x[i,:,:,:], train_speed_y[i,:,:], batch_size=batch_size, verbose=0))\n",
    "# trainScore = np.mean(trainScore)\n",
    "# print('Train Score: ', trainScore)\n",
    "# testScore = [];\n",
    "# for i in range(len(test_speed_x)):\n",
    "#     testScore.append(model.evaluate(test_speed_x[i,:,:,:], test_speed_y[i,:,:], batch_size=batch_size, verbose=0))\n",
    "# testScore = np.mean(testScore)\n",
    "# print('Test Score: ', testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch_size = 1\n",
    "\n",
    "look_ahead = 60\n",
    "start = 0\n",
    "trainPredict = test_speed_x[0,start,:,:]\n",
    "predictions = np.zeros((look_ahead,1))\n",
    "\n",
    "for i in range(look_ahead):\n",
    "    prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "    predictions[i] = prediction\n",
    "    trainPredict = np.vstack([trainPredict[1:],prediction])\n",
    "    \n",
    "fig1 = plt.figure(figsize=(12,10))\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1.set_title('prediction at the start of day', fontsize=20)\n",
    "plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n",
    "plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),0],label=\"test function\")\n",
    "plt.legend()\n",
    "\n",
    "predictions = np.zeros((look_ahead,1))\n",
    "\n",
    "for i in range(look_ahead):\n",
    "    trainPredict = test_speed_x[0,start+i,:,:]\n",
    "    prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "    predictions[i] = prediction\n",
    "    \n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2.set_title('prediction using real-time data', fontsize=20)\n",
    "plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n",
    "plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),0],label=\"test function\")\n",
    "plt.legend()\n",
    "\n",
    "fig1.savefig('test_output_exp1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment2: speed to speed univariate, same day of week, stateless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_speed = Speed[-1:,:,:]\n",
    "dayofweek = data['dayofweek'][len(data)-1]\n",
    "train_speed = Speed[data.index[data['dayofweek'] == dayofweek],:,:]\n",
    "train_speed = train_speed[:-1,:,:]\n",
    "print('train_speed.shape = ',train_speed.shape)\n",
    "print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "look_back = 15\n",
    "mode = 'uni'\n",
    "train_speed_x,train_speed_y = create_dataset(train_speed, look_back, mode)\n",
    "test_speed_x,test_speed_y = create_dataset(test_speed, look_back, mode)\n",
    "print('look_back = ',look_back)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "epochs = 2\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(look_back, 1), stateful=False, return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, input_shape=(look_back, 1), stateful=False))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "train_x = np.reshape(train_speed_x,(49*1424,15,1))\n",
    "train_y = np.reshape(train_speed_y,(49*1424,1))\n",
    "h2 = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### plot the training and validation loss for each epoch\n",
    "fig2 = plt.figure(figsize=(15,5))\n",
    "plt.plot(h2.history['loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "\n",
    "fig2.savefig('train_history_exp2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch_size = 1\n",
    "\n",
    "look_ahead = 60\n",
    "start = 0\n",
    "trainPredict = test_speed_x[0,start,:,:]\n",
    "predictions = np.zeros((look_ahead,1))\n",
    "\n",
    "for i in range(look_ahead):\n",
    "    prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "    predictions[i] = prediction\n",
    "    trainPredict = np.vstack([trainPredict[1:],prediction])\n",
    "    \n",
    "fig3 = plt.figure(figsize=(12,10))\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1.set_title('prediction at the start of day', fontsize=20)\n",
    "plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n",
    "plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),0],label=\"test function\")\n",
    "plt.legend()\n",
    "\n",
    "predictions = np.zeros((look_ahead,1))\n",
    "\n",
    "for i in range(look_ahead):\n",
    "    trainPredict = test_speed_x[0,start+i,:,:]\n",
    "    prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "    predictions[i] = prediction\n",
    "    \n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2.set_title('prediction using real-time data', fontsize=20)\n",
    "plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n",
    "plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),0],label=\"test function\")\n",
    "plt.legend()\n",
    "\n",
    "fig3.savefig('test_output_exp2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment3: speed to speed univariate, last month, stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment4: speed to speed univariate, last month, stateless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_speed = Speed[-1:,:,:]\n",
    "# dayofweek = data['dayofweek'][len(data)-1]\n",
    "# train_speed = Speed[data.index[data['dayofweek'] == dayofweek],:,:]\n",
    "train_speed = Speed[:-1,:,:]\n",
    "print('train_speed.shape = ',train_speed.shape)\n",
    "print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "look_back = 15\n",
    "mode = 'uni'\n",
    "train_speed_x,train_speed_y = create_dataset(train_speed, look_back, mode)\n",
    "test_speed_x,test_speed_y = create_dataset(test_speed, look_back, mode)\n",
    "print('look_back = ',look_back)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "epochs = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(look_back, 1), stateful=False, return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, input_shape=(look_back, 1), stateful=False))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "train_x = np.reshape(train_speed_x,(345*1424,15,1))\n",
    "train_y = np.reshape(train_speed_y,(345*1424,1))\n",
    "h4 = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### plot the training and validation loss for each epoch\n",
    "fig4 = plt.figure(figsize=(15,5))\n",
    "plt.plot(h2.history['loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "\n",
    "fig4.savefig('train_history_exp4.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size = 1\n",
    "\n",
    "look_ahead = 60\n",
    "start = 0\n",
    "trainPredict = test_speed_x[0,start,:,:]\n",
    "predictions = np.zeros((look_ahead,1))\n",
    "\n",
    "for i in range(look_ahead):\n",
    "    prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "    predictions[i] = prediction\n",
    "    trainPredict = np.vstack([trainPredict[1:],prediction])\n",
    "    \n",
    "fig5 = plt.figure(figsize=(12,10))\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1.set_title('prediction at the start of day', fontsize=20)\n",
    "plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n",
    "plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),0],label=\"test function\")\n",
    "plt.legend()\n",
    "\n",
    "predictions = np.zeros((look_ahead,1))\n",
    "\n",
    "for i in range(look_ahead):\n",
    "    trainPredict = test_speed_x[0,start+i,:,:]\n",
    "    prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "    predictions[i] = prediction\n",
    "    \n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2.set_title('prediction using real-time data', fontsize=20)\n",
    "plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n",
    "plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),0],label=\"test function\")\n",
    "plt.legend()\n",
    "\n",
    "fig5.savefig('test_output_exp4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment5: speed to speed multivariate, best of above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment6: speed, volumn, occup to speed univariate, best of above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment6: speed, volumn, occup to speed multivariate, best of above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND]",
   "language": "python",
   "name": "conda-env-CarND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
